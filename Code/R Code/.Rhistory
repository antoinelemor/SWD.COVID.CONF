# Reduce the dataset to selected columns
redux <- uncertainty_count_persons %>% select(ID, date, UNC)
# Validate the variables
library(dplyr)
# Randomly select 100 rows based on the specified conditions
Evidence_validate <- QC.unc.data_persanddict_redux %>%
filter(expertise == 1 & dictionary_strong == 1 & (Legault == 1 | Dubé == 1 | McCann == 1 | Guilbault == 1)) %>%
select(date, doc_id, unique_phrase_id, sentence) %>%
sample_n(100)
# Save the dataframe as .csv
output_file <- file.path(export_path, "EXP_validate.csv")
write.csv(Evidence_validate, file = output_file, row.names = FALSE)
# Randomly select 100 rows based on the new conditions
Uncertainty_validate <- QC.unc.data_persanddict_redux %>%
filter(uncertainty == 1 & dictionary_strong == 1 & (Legault == 1 | Dubé == 1 | McCann == 1 | Guilbault == 1 | Arruda == 1 | Boileau == 1)) %>%
select(date, doc_id, unique_phrase_id, sentence) %>%
sample_n(100)
# Save the new dataframe as .csv
output_file <- file.path(export_path, "UDictFull_validate.csv")
write.csv(Uncertainty_validate, file = output_file, row.names = FALSE)
# Randomly select 100 rows based on the specified conditions for PolDicFullneg
PolDicFullneg_validate <- QC.unc.data_persanddict_redux %>%
filter(polarity_sentence < 0 & dictionary_strong == 1 & (Legault == 1 | Dubé == 1 | McCann == 1 | Guilbault == 1)) %>%
select(date, doc_id, unique_phrase_id, sentence) %>%
sample_n(100)
# Save the new dataframe as .csv
output_file <- file.path(export_path, "PolDicFullneg_validate.csv")
write.csv(PolDicFullneg_validate, file = output_file, row.names = FALSE)
# Packages
#  Packages
library(tidyverse)
library(dplyr)
library(readxl)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
# Load the datasets
QC_data_file <- file.path(import_data_path, "QC.IRPPstringency_data.csv")
QC_data <- read.csv(QC_data_file, stringsAsFactors = FALSE)
Unc_persdict_file <- file.path(import_data_path, "QC.unc_data_persanddict_daily.csv")
Unc_persdict <- read.csv(Unc_persdict_file, stringsAsFactors = FALSE, sep=",")
hospi_file <- file.path(import_data_path, "QC.COVID_data.xlsx")
hospi <- read_excel(hospi_file, sheet = 1)
vacc_file <- file.path(import_data_path, "QC.vax_data.csv")
vacc <- read_csv2(vacc_file)
# Standardize dates by creating an ID identifier variable
# Load the 'hospi', 'vacc', 'Unc_persdict', and 'QC_data' datasets
library(dplyr)
Unc_persdict$ID <- NULL
# Convert the 'date' variable to 'datetime' in the 'vacc' dataset
vacc$date <- as.POSIXct(vacc$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.POSIXct(Unc_persdict$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'QC_data' dataset
QC_data$date <- as.POSIXct(QC_data$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'date' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.Date(Unc_persdict$date, format="%Y-%m-%d %H:%M:%S")
# Convert the 'date' variable to 'date' in the 'QC_data' dataset
QC_data$date <- as.Date(QC_data$date, format="%Y-%m-%d %H:%M:%S")
# Create a vector of all dates
all_dates <- sort(unique(c(hospi$date, vacc$date, Unc_persdict$date, QC_data$date)))
# Create a lookup table for dates and IDs
date_id_table <- data.frame(date = all_dates, ID = seq_along(all_dates))
# Merge the lookup tables with the datasets
hospi <- left_join(hospi, date_id_table, by = "date")
vacc <- left_join(vacc, date_id_table, by = "date")
Unc_persdict <- left_join(Unc_persdict, date_id_table, by = "date")
QC_data <- left_join(QC_data, date_id_table, by = "date")
QC_data$ID <- as.numeric(QC_data$ID)
vacc$ID <- as.numeric(vacc$ID)
Unc_persdict$ID <- as.numeric(Unc_persdict$ID)
hospi$ID <- as.numeric(hospi$ID)
# Merge datasets and fill in dates with ID
QC.unc.data_merge <- QC_data[,c("ID","date","stringencyPHM", "stringencyIndex")]
QC.unc.data_merge <- merge(QC.unc.data_merge, Unc_persdict[, c("ID", "EVD", "NEG", "UNC", "UNC_PROP")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, hospi[, c("ID", "hospi_total", "cases", "death")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, vacc[, c("ID", "VAX")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge$date <- as.Date("2020-02-27") + (QC.unc.data_merge$ID - 1)
# Create a 'wave' variable identifying each wave
QC.unc.data_daily <- QC.unc.data_merge
QC.unc.data_daily$wave = ifelse(QC.unc.data_daily$date >= as.Date("2020-02-25") & QC.unc.data_daily$date <= as.Date("2020-07-11"), 1,
ifelse(QC.unc.data_daily$date >= as.Date("2020-07-12") & QC.unc.data_daily$date <= as.Date("2021-03-20"), 2,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-21") & QC.unc.data_daily$date <= as.Date("2021-07-17"), 3,
ifelse(QC.unc.data_daily$date >= as.Date("2021-07-18") & QC.unc.data_daily$date <= as.Date("2021-12-05"), 4,
ifelse(QC.unc.data_daily$date >= as.Date("2021-12-06") & QC.unc.data_daily$date <= as.Date("2022-03-17"), 5,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-18") & QC.unc.data_daily$date <= as.Date("2022-05-28"), 6,
NA))))))
# Rename variables
QC.unc.data_daily <- rename(QC.unc.data_daily,
SPHM = "stringencyPHM",
SI = "stringencyIndex",
TH = "hospi_total",
CC = "cases",
CD = "death")
# Rescale hostpialization to 100 (TH100)
QC.unc.data_daily$TH100 <- ifelse(is.na(QC.unc.data_daily$TH),NA,(QC.unc.data_daily$TH-min(QC.unc.data_daily$TH,na.rm=T))/(max(QC.unc.data_daily$TH,na.rm=T)-min(QC.unc.data_daily$TH,na.rm=T))*100)
# Rescale vaccination to 100 (VAX100)
QC.unc.data_daily$VAX100 <- ifelse(is.na(QC.unc.data_daily$VAX),NA,(QC.unc.data_daily$VAX-min(QC.unc.data_daily$VAX,na.rm=T))/(max(QC.unc.data_daily$VAX,na.rm=T)-min(QC.unc.data_daily$VAX,na.rm=T))*100)
# Rescale Cases to 100 (CC100)
QC.unc.data_daily$CC100 <- ifelse(is.na(QC.unc.data_daily$CC),NA,(QC.unc.data_daily$CC-min(QC.unc.data_daily$CC,na.rm=T))/(max(QC.unc.data_daily$CC,na.rm=T)-min(QC.unc.data_daily$CC,na.rm=T))*100)
# Rescale Death to 100 (CD100)
QC.unc.data_daily$CD100 <- ifelse(is.na(QC.unc.data_daily$CD),NA,(QC.unc.data_daily$CD-min(QC.unc.data_daily$CD,na.rm=T))/(max(QC.unc.data_daily$CD,na.rm=T)-min(QC.unc.data_daily$CD,na.rm=T))*100)
# Delete lines after the last value of SPHM
QC.unc.data_daily <- QC.unc.data_daily %>% filter(ID <= 810)
# Organize the database
QC.unc.data_daily <- QC.unc.data_daily %>%
select(ID, date, wave, SPHM, SI, UNC, EVD, NEG, CC100, CD100, TH100, VAX100, CC, CD, TH, VAX)
# Export database
output_file <- file.path(export_path, "QC.unc.data_daily.csv")
write.csv(QC.unc.data_daily, file = output_file, row.names = FALSE)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Results"
# Importing the database
input_file <- file.path(import_data_path, "QC.unc.data_daily.csv")
reg_data_daily <- read.csv(input_file, header = TRUE, sep=",")
## CREATING THE GENERAL GRAPH ##
# Packages
library(ggplot2)
library(scales)
library(tidyverse)
# Graph
reg_data_daily$date <- as.Date(reg_data_daily$date)
wave_dates <- c("2020-02-25", "2020-08-23", "2021-03-20", "2021-07-17", "2021-12-05", "2022-03-12")
wave_labels <- c("Wave 1", "Wave 2", "Wave 3", "Wave 4", "Wave 5", "Wave 6")
se_fill <- "#D3D3D3"
p <- ggplot(data = reg_data_daily, aes(x = date)) +
geom_smooth(aes(y = SPHM, color = "Stringency"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = EVD, color = "Evidence"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = UNC_PROP, color = "Uncertainty"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = NEG, color = "Negative sentiments"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
scale_color_manual(name = NULL,
values = c("Stringency" = "#df0806",
"Uncertainty" = "black",
"Evidence" = "#006400",
"Negative sentiments" = "grey",
"Uncertainty" = "black"),
breaks = c("Stringency", "Projections", "Uncertainty", "Negative sentiments", "Evidence")) +
scale_y_continuous(limits = c(0, NA)) +
theme(plot.title = element_text(face = "bold", size = 25, hjust = 0.5),
axis.text.y = element_text(face = "bold", size = 25),
legend.text = element_text(face = "bold", size = 25),
legend.key.size = unit(1.8, "cm"),
legend.position = "top",
legend.background = element_rect(fill = "#DCDCDC", color = "black"),
legend.key = element_rect(fill = "#DCDCDC", color = NA),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(face = "bold", angle = 45, hjust = 1, size = 25),
legend.justification = c(0.5, 0.5), legend.box.just = "center") +
guides(color = guide_legend(nrow = 1)) +
geom_vline(xintercept = as.Date(wave_dates), linetype = "dashed", color = "black") +
annotate("text", x = as.Date(c("2020-05-01", "2020-11-15", "2021-04-28", "2021-09-05", "2022-01-01", "2022-04-12")), y = Inf, label = wave_labels, vjust = 2, hjust = 0, size = 7, color = "black", fontface = "bold") +
scale_x_date(breaks = seq(as.Date("2020-03-01"), as.Date("2022-06-01"), by = "1 month"), date_labels = "%b-%Y")
print(p)
# Packages
#  Packages
library(tidyverse)
library(dplyr)
library(readxl)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
# Load the datasets
QC_data_file <- file.path(import_data_path, "QC.IRPPstringency_data.csv")
QC_data <- read.csv(QC_data_file, stringsAsFactors = FALSE)
Unc_persdict_file <- file.path(import_data_path, "QC.unc_data_persanddict_daily.csv")
Unc_persdict <- read.csv(Unc_persdict_file, stringsAsFactors = FALSE, sep=",")
hospi_file <- file.path(import_data_path, "QC.COVID_data.xlsx")
hospi <- read_excel(hospi_file, sheet = 1)
vacc_file <- file.path(import_data_path, "QC.vax_data.csv")
vacc <- read_csv2(vacc_file)
# Standardize dates by creating an ID identifier variable
# Load the 'hospi', 'vacc', 'Unc_persdict', and 'QC_data' datasets
library(dplyr)
Unc_persdict$ID <- NULL
# Convert the 'date' variable to 'datetime' in the 'vacc' dataset
vacc$date <- as.POSIXct(vacc$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.POSIXct(Unc_persdict$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'QC_data' dataset
QC_data$date <- as.POSIXct(QC_data$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'date' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.Date(Unc_persdict$date, format="%Y-%m-%d %H:%M:%S")
# Convert the 'date' variable to 'date' in the 'QC_data' dataset
QC_data$date <- as.Date(QC_data$date, format="%Y-%m-%d %H:%M:%S")
# Create a vector of all dates
all_dates <- sort(unique(c(hospi$date, vacc$date, Unc_persdict$date, QC_data$date)))
# Create a lookup table for dates and IDs
date_id_table <- data.frame(date = all_dates, ID = seq_along(all_dates))
# Merge the lookup tables with the datasets
hospi <- left_join(hospi, date_id_table, by = "date")
vacc <- left_join(vacc, date_id_table, by = "date")
Unc_persdict <- left_join(Unc_persdict, date_id_table, by = "date")
QC_data <- left_join(QC_data, date_id_table, by = "date")
QC_data$ID <- as.numeric(QC_data$ID)
vacc$ID <- as.numeric(vacc$ID)
Unc_persdict$ID <- as.numeric(Unc_persdict$ID)
hospi$ID <- as.numeric(hospi$ID)
# Merge datasets and fill in dates with ID
QC.unc.data_merge <- QC_data[,c("ID","date","stringencyPHM", "stringencyIndex")]
QC.unc.data_merge <- merge(QC.unc.data_merge, Unc_persdict[, c("ID", "EVD", "NEG", "UNC", "UNC_PROP")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, hospi[, c("ID", "hospi_total", "cases", "death")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, vacc[, c("ID", "VAX")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge$date <- as.Date("2020-02-27") + (QC.unc.data_merge$ID - 1)
# Create a 'wave' variable identifying each wave
QC.unc.data_daily <- QC.unc.data_merge
QC.unc.data_daily$wave = ifelse(QC.unc.data_daily$date >= as.Date("2020-02-25") & QC.unc.data_daily$date <= as.Date("2020-07-11"), 1,
ifelse(QC.unc.data_daily$date >= as.Date("2020-07-12") & QC.unc.data_daily$date <= as.Date("2021-03-20"), 2,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-21") & QC.unc.data_daily$date <= as.Date("2021-07-17"), 3,
ifelse(QC.unc.data_daily$date >= as.Date("2021-07-18") & QC.unc.data_daily$date <= as.Date("2021-12-05"), 4,
ifelse(QC.unc.data_daily$date >= as.Date("2021-12-06") & QC.unc.data_daily$date <= as.Date("2022-03-17"), 5,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-18") & QC.unc.data_daily$date <= as.Date("2022-05-28"), 6,
NA))))))
# Rename variables
QC.unc.data_daily <- rename(QC.unc.data_daily,
SPHM = "stringencyPHM",
SI = "stringencyIndex",
TH = "hospi_total",
CC = "cases",
CD = "death")
# Rescale hostpialization to 100 (TH100)
QC.unc.data_daily$TH100 <- ifelse(is.na(QC.unc.data_daily$TH),NA,(QC.unc.data_daily$TH-min(QC.unc.data_daily$TH,na.rm=T))/(max(QC.unc.data_daily$TH,na.rm=T)-min(QC.unc.data_daily$TH,na.rm=T))*100)
# Rescale vaccination to 100 (VAX100)
QC.unc.data_daily$VAX100 <- ifelse(is.na(QC.unc.data_daily$VAX),NA,(QC.unc.data_daily$VAX-min(QC.unc.data_daily$VAX,na.rm=T))/(max(QC.unc.data_daily$VAX,na.rm=T)-min(QC.unc.data_daily$VAX,na.rm=T))*100)
# Rescale Cases to 100 (CC100)
QC.unc.data_daily$CC100 <- ifelse(is.na(QC.unc.data_daily$CC),NA,(QC.unc.data_daily$CC-min(QC.unc.data_daily$CC,na.rm=T))/(max(QC.unc.data_daily$CC,na.rm=T)-min(QC.unc.data_daily$CC,na.rm=T))*100)
# Rescale Death to 100 (CD100)
QC.unc.data_daily$CD100 <- ifelse(is.na(QC.unc.data_daily$CD),NA,(QC.unc.data_daily$CD-min(QC.unc.data_daily$CD,na.rm=T))/(max(QC.unc.data_daily$CD,na.rm=T)-min(QC.unc.data_daily$CD,na.rm=T))*100)
# Delete lines after the last value of SPHM
QC.unc.data_daily <- QC.unc.data_daily %>% filter(ID <= 810)
# Organize the database
QC.unc.data_daily <- QC.unc.data_daily %>%
select(ID, date, wave, SPHM, SI, UNC, EVD, NEG, CC100, CD100, TH100, VAX100, CC, CD, TH, VAX)
# Export database
output_file <- file.path(export_path, "QC.unc.data_daily.csv")
write.csv(QC.unc.data_daily, file = output_file, row.names = FALSE)
# Packages
#  Packages
library(tidyverse)
library(dplyr)
library(readxl)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
# Load the datasets
QC_data_file <- file.path(import_data_path, "QC.IRPPstringency_data.csv")
QC_data <- read.csv(QC_data_file, stringsAsFactors = FALSE)
Unc_persdict_file <- file.path(import_data_path, "QC.unc_data_persanddict_daily.csv")
Unc_persdict <- read.csv(Unc_persdict_file, stringsAsFactors = FALSE, sep=",")
hospi_file <- file.path(import_data_path, "QC.COVID_data.xlsx")
hospi <- read_excel(hospi_file, sheet = 1)
vacc_file <- file.path(import_data_path, "QC.vax_data.csv")
vacc <- read_csv2(vacc_file)
# Standardize dates by creating an ID identifier variable
# Load the 'hospi', 'vacc', 'Unc_persdict', and 'QC_data' datasets
library(dplyr)
Unc_persdict$ID <- NULL
# Convert the 'date' variable to 'datetime' in the 'vacc' dataset
vacc$date <- as.POSIXct(vacc$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.POSIXct(Unc_persdict$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'QC_data' dataset
QC_data$date <- as.POSIXct(QC_data$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'date' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.Date(Unc_persdict$date, format="%Y-%m-%d %H:%M:%S")
# Convert the 'date' variable to 'date' in the 'QC_data' dataset
QC_data$date <- as.Date(QC_data$date, format="%Y-%m-%d %H:%M:%S")
# Create a vector of all dates
all_dates <- sort(unique(c(hospi$date, vacc$date, Unc_persdict$date, QC_data$date)))
# Create a lookup table for dates and IDs
date_id_table <- data.frame(date = all_dates, ID = seq_along(all_dates))
# Merge the lookup tables with the datasets
hospi <- left_join(hospi, date_id_table, by = "date")
vacc <- left_join(vacc, date_id_table, by = "date")
Unc_persdict <- left_join(Unc_persdict, date_id_table, by = "date")
QC_data <- left_join(QC_data, date_id_table, by = "date")
QC_data$ID <- as.numeric(QC_data$ID)
vacc$ID <- as.numeric(vacc$ID)
Unc_persdict$ID <- as.numeric(Unc_persdict$ID)
hospi$ID <- as.numeric(hospi$ID)
# Merge datasets and fill in dates with ID
QC.unc.data_merge <- QC_data[,c("ID","date","stringencyPHM", "stringencyIndex")]
QC.unc.data_merge <- merge(QC.unc.data_merge, Unc_persdict[, c("ID", "EVD", "NEG", "UNC", "UNC_PROP")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, hospi[, c("ID", "hospi_total", "cases", "death")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, vacc[, c("ID", "VAX")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge$date <- as.Date("2020-02-27") + (QC.unc.data_merge$ID - 1)
# Create a 'wave' variable identifying each wave
QC.unc.data_daily <- QC.unc.data_merge
QC.unc.data_daily$wave = ifelse(QC.unc.data_daily$date >= as.Date("2020-02-25") & QC.unc.data_daily$date <= as.Date("2020-07-11"), 1,
ifelse(QC.unc.data_daily$date >= as.Date("2020-07-12") & QC.unc.data_daily$date <= as.Date("2021-03-20"), 2,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-21") & QC.unc.data_daily$date <= as.Date("2021-07-17"), 3,
ifelse(QC.unc.data_daily$date >= as.Date("2021-07-18") & QC.unc.data_daily$date <= as.Date("2021-12-05"), 4,
ifelse(QC.unc.data_daily$date >= as.Date("2021-12-06") & QC.unc.data_daily$date <= as.Date("2022-03-17"), 5,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-18") & QC.unc.data_daily$date <= as.Date("2022-05-28"), 6,
NA))))))
# Rename variables
QC.unc.data_daily <- rename(QC.unc.data_daily,
SPHM = "stringencyPHM",
SI = "stringencyIndex",
TH = "hospi_total",
CC = "cases",
CD = "death")
# Packages
#  Packages
library(tidyverse)
library(dplyr)
library(readxl)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
# Load the datasets
QC_data_file <- file.path(import_data_path, "QC.IRPPstringency_data.csv")
QC_data <- read.csv(QC_data_file, stringsAsFactors = FALSE)
Unc_persdict_file <- file.path(import_data_path, "QC.unc_data_persanddict_daily.csv")
Unc_persdict <- read.csv(Unc_persdict_file, stringsAsFactors = FALSE, sep=",")
hospi_file <- file.path(import_data_path, "QC.COVID_data.xlsx")
hospi <- read_excel(hospi_file, sheet = 1)
vacc_file <- file.path(import_data_path, "QC.vax_data.csv")
vacc <- read_csv2(vacc_file)
# Standardize dates by creating an ID identifier variable
# Load the 'hospi', 'vacc', 'Unc_persdict', and 'QC_data' datasets
library(dplyr)
Unc_persdict$ID <- NULL
# Convert the 'date' variable to 'datetime' in the 'vacc' dataset
vacc$date <- as.POSIXct(vacc$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.POSIXct(Unc_persdict$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'datetime' in the 'QC_data' dataset
QC_data$date <- as.POSIXct(QC_data$date, format="%Y-%m-%d")
# Convert the 'date' variable to 'date' in the 'Unc_persdict' dataset
Unc_persdict$date <- as.Date(Unc_persdict$date, format="%Y-%m-%d %H:%M:%S")
# Convert the 'date' variable to 'date' in the 'QC_data' dataset
QC_data$date <- as.Date(QC_data$date, format="%Y-%m-%d %H:%M:%S")
# Create a vector of all dates
all_dates <- sort(unique(c(hospi$date, vacc$date, Unc_persdict$date, QC_data$date)))
# Create a lookup table for dates and IDs
date_id_table <- data.frame(date = all_dates, ID = seq_along(all_dates))
# Merge the lookup tables with the datasets
hospi <- left_join(hospi, date_id_table, by = "date")
vacc <- left_join(vacc, date_id_table, by = "date")
Unc_persdict <- left_join(Unc_persdict, date_id_table, by = "date")
QC_data <- left_join(QC_data, date_id_table, by = "date")
QC_data$ID <- as.numeric(QC_data$ID)
vacc$ID <- as.numeric(vacc$ID)
Unc_persdict$ID <- as.numeric(Unc_persdict$ID)
hospi$ID <- as.numeric(hospi$ID)
# Merge datasets and fill in dates with ID
QC.unc.data_merge <- QC_data[,c("ID","date","stringencyPHM", "stringencyIndex")]
QC.unc.data_merge <- merge(QC.unc.data_merge, Unc_persdict[, c("ID", "EVD", "NEG", "UNC", "UNC_PROP")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, hospi[, c("ID", "hospi_total", "cases", "death")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge <- merge(QC.unc.data_merge, vacc[, c("ID", "VAX")], by = "ID", all = TRUE, na.rm = TRUE)
QC.unc.data_merge$date <- as.Date("2020-02-27") + (QC.unc.data_merge$ID - 1)
# Create a 'wave' variable identifying each wave
QC.unc.data_daily <- QC.unc.data_merge
QC.unc.data_daily$wave = ifelse(QC.unc.data_daily$date >= as.Date("2020-02-25") & QC.unc.data_daily$date <= as.Date("2020-07-11"), 1,
ifelse(QC.unc.data_daily$date >= as.Date("2020-07-12") & QC.unc.data_daily$date <= as.Date("2021-03-20"), 2,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-21") & QC.unc.data_daily$date <= as.Date("2021-07-17"), 3,
ifelse(QC.unc.data_daily$date >= as.Date("2021-07-18") & QC.unc.data_daily$date <= as.Date("2021-12-05"), 4,
ifelse(QC.unc.data_daily$date >= as.Date("2021-12-06") & QC.unc.data_daily$date <= as.Date("2022-03-17"), 5,
ifelse(QC.unc.data_daily$date >= as.Date("2021-03-18") & QC.unc.data_daily$date <= as.Date("2022-05-28"), 6,
NA))))))
# Rename variables
QC.unc.data_daily <- rename(QC.unc.data_daily,
SPHM = "stringencyPHM",
SI = "stringencyIndex",
TH = "hospi_total",
CC = "cases",
CD = "death")
# Rescale hostpialization to 100 (TH100)
QC.unc.data_daily$TH100 <- ifelse(is.na(QC.unc.data_daily$TH),NA,(QC.unc.data_daily$TH-min(QC.unc.data_daily$TH,na.rm=T))/(max(QC.unc.data_daily$TH,na.rm=T)-min(QC.unc.data_daily$TH,na.rm=T))*100)
# Rescale vaccination to 100 (VAX100)
QC.unc.data_daily$VAX100 <- ifelse(is.na(QC.unc.data_daily$VAX),NA,(QC.unc.data_daily$VAX-min(QC.unc.data_daily$VAX,na.rm=T))/(max(QC.unc.data_daily$VAX,na.rm=T)-min(QC.unc.data_daily$VAX,na.rm=T))*100)
# Rescale Cases to 100 (CC100)
QC.unc.data_daily$CC100 <- ifelse(is.na(QC.unc.data_daily$CC),NA,(QC.unc.data_daily$CC-min(QC.unc.data_daily$CC,na.rm=T))/(max(QC.unc.data_daily$CC,na.rm=T)-min(QC.unc.data_daily$CC,na.rm=T))*100)
# Rescale Death to 100 (CD100)
QC.unc.data_daily$CD100 <- ifelse(is.na(QC.unc.data_daily$CD),NA,(QC.unc.data_daily$CD-min(QC.unc.data_daily$CD,na.rm=T))/(max(QC.unc.data_daily$CD,na.rm=T)-min(QC.unc.data_daily$CD,na.rm=T))*100)
# Delete lines after the last value of SPHM
QC.unc.data_daily <- QC.unc.data_daily %>% filter(ID <= 810)
# Organize the database
QC.unc.data_daily <- QC.unc.data_daily %>%
select(ID, date, wave, SPHM, SI, UNC, UNC_PROP, EVD, NEG, CC100, CD100, TH100, VAX100, CC, CD, TH, VAX)
# Export database
output_file <- file.path(export_path, "QC.unc.data_daily.csv")
write.csv(QC.unc.data_daily, file = output_file, row.names = FALSE)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Results"
# Importing the database
input_file <- file.path(import_data_path, "QC.unc.data_daily.csv")
reg_data_daily <- read.csv(input_file, header = TRUE, sep=",")
## CREATING THE GENERAL GRAPH ##
# Packages
library(ggplot2)
library(scales)
library(tidyverse)
# Graph
reg_data_daily$date <- as.Date(reg_data_daily$date)
wave_dates <- c("2020-02-25", "2020-08-23", "2021-03-20", "2021-07-17", "2021-12-05", "2022-03-12")
wave_labels <- c("Wave 1", "Wave 2", "Wave 3", "Wave 4", "Wave 5", "Wave 6")
se_fill <- "#D3D3D3"
p <- ggplot(data = reg_data_daily, aes(x = date)) +
geom_smooth(aes(y = SPHM, color = "Stringency"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = EVD, color = "Evidence"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = UNC_PROP, color = "Uncertainty"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = NEG, color = "Negative sentiments"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
scale_color_manual(name = NULL,
values = c("Stringency" = "#df0806",
"Uncertainty" = "black",
"Evidence" = "#006400",
"Negative sentiments" = "grey",
"Uncertainty" = "black"),
breaks = c("Stringency", "Projections", "Uncertainty", "Negative sentiments", "Evidence")) +
scale_y_continuous(limits = c(0, NA)) +
theme(plot.title = element_text(face = "bold", size = 25, hjust = 0.5),
axis.text.y = element_text(face = "bold", size = 25),
legend.text = element_text(face = "bold", size = 25),
legend.key.size = unit(1.8, "cm"),
legend.position = "top",
legend.background = element_rect(fill = "#DCDCDC", color = "black"),
legend.key = element_rect(fill = "#DCDCDC", color = NA),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(face = "bold", angle = 45, hjust = 1, size = 25),
legend.justification = c(0.5, 0.5), legend.box.just = "center") +
guides(color = guide_legend(nrow = 1)) +
geom_vline(xintercept = as.Date(wave_dates), linetype = "dashed", color = "black") +
annotate("text", x = as.Date(c("2020-05-01", "2020-11-15", "2021-04-28", "2021-09-05", "2022-01-01", "2022-04-12")), y = Inf, label = wave_labels, vjust = 2, hjust = 0, size = 7, color = "black", fontface = "bold") +
scale_x_date(breaks = seq(as.Date("2020-03-01"), as.Date("2022-06-01"), by = "1 month"), date_labels = "%b-%Y")
print(p)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Results"
# Importing the database
input_file <- file.path(import_data_path, "QC.unc.data_daily.csv")
reg_data_daily <- read.csv(input_file, header = TRUE, sep=",")
## CREATING THE GENERAL GRAPH ##
# Packages
library(ggplot2)
library(scales)
library(tidyverse)
# Graph
reg_data_daily$date <- as.Date(reg_data_daily$date)
wave_dates <- c("2020-02-25", "2020-08-23", "2021-03-20", "2021-07-17", "2021-12-05", "2022-03-12")
wave_labels <- c("Wave 1", "Wave 2", "Wave 3", "Wave 4", "Wave 5", "Wave 6")
se_fill <- "#D3D3D3"
p <- ggplot(data = reg_data_daily, aes(x = date)) +
geom_smooth(aes(y = SPHM, color = "Stringency"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = EVD, color = "Evidence"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
geom_smooth(aes(y = UNC_PROP, color = "Uncertainty"), method = "loess", span = 0.10, se = FALSE, size = 2.3) +
geom_smooth(aes(y = NEG, color = "Negative sentiments"), method = "loess", span = 0.37, se = FALSE, size = 2.3) +
scale_color_manual(name = NULL,
values = c("Stringency" = "#df0806",
"Uncertainty" = "black",
"Evidence" = "#006400",
"Negative sentiments" = "grey",
"Uncertainty" = "black"),
breaks = c("Stringency", "Projections", "Uncertainty", "Negative sentiments", "Evidence")) +
scale_y_continuous(limits = c(0, NA)) +
theme(plot.title = element_text(face = "bold", size = 25, hjust = 0.5),
axis.text.y = element_text(face = "bold", size = 25),
legend.text = element_text(face = "bold", size = 25),
legend.key.size = unit(1.8, "cm"),
legend.position = "top",
legend.background = element_rect(fill = "#DCDCDC", color = "black"),
legend.key = element_rect(fill = "#DCDCDC", color = NA),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(face = "bold", angle = 45, hjust = 1, size = 25),
legend.justification = c(0.5, 0.5), legend.box.just = "center") +
guides(color = guide_legend(nrow = 1)) +
geom_vline(xintercept = as.Date(wave_dates), linetype = "dashed", color = "black") +
annotate("text", x = as.Date(c("2020-05-01", "2020-11-15", "2021-04-28", "2021-09-05", "2022-01-01", "2022-04-12")), y = Inf, label = wave_labels, vjust = 2, hjust = 0, size = 7, color = "black", fontface = "bold") +
scale_x_date(breaks = seq(as.Date("2020-03-01"), as.Date("2022-06-01"), by = "1 month"), date_labels = "%b-%Y")
print(p)
# Packages
library(modelsummary)
# Base path
import_data_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Database"
export_path <- "/Users/antoine/Documents/GitHub.nosync/Uncertainty_COVID_QC/Data/Results"
# Importing the database
input_file <- file.path(import_data_path, "QC.unc.data_daily.csv")
reg_data_daily <- read.csv(input_file, header = TRUE, sep=",")
## OLS MODELS ##
# Packages
library(modelsummary)
library(flextable)
library(tidyverse)
library(officer)
library(knitr)
library(kableExtra)
# Models
models <- list()
models[['OLS1']] =lm(lead(SPHM, 1) ~ UNC_PROP+CD100+CC100+TH100+lag(SPHM, 1), data = reg_data_daily[reg_data_daily$wave %in% c(1,2,3,4,5),])
models[['OLS2']] =lm(lead(SPHM, 1) ~ UNC_PROP+NEG+CD100+CC100+TH100+lag(SPHM, 1), data = reg_data_daily[reg_data_daily$wave %in% c(1,2,3,4,5),])
models[['OLS3']] =lm(lead(SPHM, 1) ~ UNC_PROP+EVD+CD100+CC100+TH100+NEG+lag(SPHM, 1), data = reg_data_daily[reg_data_daily$wave %in% c(1,2,3,4,5),])
models[['OLS4']] =lm(lead(SPHM, 1) ~ UNC_PROP+EVD+CD100+CC100+TH100+NEG+UNC_PROP:EVD+lag(SPHM, 1), data = reg_data_daily[reg_data_daily$wave %in% c(1,2,3,4,5),])
cm <- c( '(Intercept)' = '(Intercept)', 'lag(SPHM, 1)'='Stringency - 1', 'CD100' = 'Death','CC100'= 'Cases' , 'TH100'='Hospitalizations','UNC_PROP'='UNC_PROPertainty' , 'NEG'='Negative sentiments','EVD'='Evidence',
'UNC_PROP:EVD'='UNC_PROPertainty * Evidence')
cap <- 'Table 1. Effects of UNC_PROPertainty, Evidence, Negative Sentiments and Epidemiological Variable on Policy Stringency: Results from OLS Regression Models'
tab<-modelsummary(models, output='flextable',  coef_map=cm, stars =TRUE, title=cap)
# Printing results
tab %>%autofit()
# Randomly select 100 rows based on the specified conditions for PolDicFullneg
PolDicFullneg_validate <- QC.unc.data_persanddict_redux %>%
filter(polarity_sentence < 0 & dictionary_strong == 1 & (Legault == 1 | Dubé == 1 | McCann == 1 | Guilbault == 1)) %>%
select(date, doc_id, unique_phrase_id, sentence) %>%
sample_n(100)
# Save the new dataframe as .csv
output_file <- file.path(export_path, "PolDicFullneg_validate.csv")
write.csv(PolDicFullneg_validate, file = output_file, row.names = FALSE)
View(SWD.conf_tokenised)
